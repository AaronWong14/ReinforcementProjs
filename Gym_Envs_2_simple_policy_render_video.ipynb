{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Gym_Envs_2_simple_policy_render_video.ipynb","provenance":[{"file_id":"1tug_bpg8RwrFOI8C6Ed-zo0OgD3yfnWy","timestamp":1584240817317},{"file_id":"18LdlDDT87eb8cCTHZsXyS9ksQPzL3i6H","timestamp":1552085242254}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"prYhQX_dTzVC","colab_type":"text"},"source":["> Here is the [link](https://colab.research.google.com/drive/18LdlDDT87eb8cCTHZsXyS9ksQPzL3i6H) to the first Python notebook presenting the preambles needed for working with Gym at Google CoLab and exploring Gym environments and simple policies. \n","\n","> This notebook presents shows how to solve some tasks with random action, assigned deterministic action, or heuristic action and how to render the process of tasks to video."]},{"cell_type":"markdown","metadata":{"id":"Oow0rc2iaDZ4","colab_type":"text"},"source":["# CoLab Preambles\n","\n","Most of the requirements of python packages are already fulfilled on CoLab. To run Gym, you have to install prerequisites like xvbf,opengl & other python-dev packages using the following codes.\n","\n","[](To be done next time: )\n","[](https://becominghuman.ai/lets-build-an-atari-ai-part-1-dqn-df57e8ff3b26)"]},{"cell_type":"code","metadata":{"id":"7wY4qZhPXotR","colab_type":"code","outputId":"0823504e-b87f-4957-c0d9-cc88b13f3577","executionInfo":{"status":"ok","timestamp":1584255818269,"user_tz":420,"elapsed":7679,"user":{"displayName":"Aaron Wong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiS9mCZyE463_E_8tYQyoLyZY7HPjP2KsUJDdWjQ=s64","userId":"04748882517196628077"}},"colab":{"base_uri":"https://localhost:8080/","height":316}},"source":["!pip install gym\n","!apt-get install python-opengl -y\n","!apt install xvfb -y"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (0.15.6)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym) (1.4.1)\n","Requirement already satisfied: cloudpickle~=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.2.2)\n","Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.4.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym) (1.12.0)\n","Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym) (1.17.5)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","python-opengl is already the newest version (3.1.0+dfsg-1).\n","0 upgraded, 0 newly installed, 0 to remove and 25 not upgraded.\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","xvfb is already the newest version (2:1.19.6-1ubuntu4.4).\n","0 upgraded, 0 newly installed, 0 to remove and 25 not upgraded.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3U99_zgNCk3t","colab_type":"code","outputId":"68512e58-8c8b-487a-e263-c80b21e9f8b0","executionInfo":{"status":"ok","timestamp":1584255822046,"user_tz":420,"elapsed":11432,"user":{"displayName":"Aaron Wong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiS9mCZyE463_E_8tYQyoLyZY7HPjP2KsUJDdWjQ=s64","userId":"04748882517196628077"}},"colab":{"base_uri":"https://localhost:8080/","height":193}},"source":["!pip install gym[atari]"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: gym[atari] in /usr/local/lib/python3.6/dist-packages (0.15.6)\n","Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (1.17.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (1.4.1)\n","Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (1.4.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (1.12.0)\n","Requirement already satisfied: cloudpickle~=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (1.2.2)\n","Requirement already satisfied: Pillow; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (6.2.2)\n","Requirement already satisfied: opencv-python; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (4.1.2.30)\n","Requirement already satisfied: atari-py~=0.2.0; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari]) (0.2.6)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[atari]) (0.16.0)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"giqCoXRwaaH3","colab_type":"text"},"source":["For rendering environment, you can use pyvirtualdisplay. So fulfill that "]},{"cell_type":"code","metadata":{"id":"yrxgO5S4XxI5","colab_type":"code","outputId":"1d7a5966-d420-4534-8da0-29b6616be575","executionInfo":{"status":"ok","timestamp":1584255827503,"user_tz":420,"elapsed":16872,"user":{"displayName":"Aaron Wong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiS9mCZyE463_E_8tYQyoLyZY7HPjP2KsUJDdWjQ=s64","userId":"04748882517196628077"}},"colab":{"base_uri":"https://localhost:8080/","height":193}},"source":["!pip install pyvirtualdisplay\n","!pip install piglet"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.6/dist-packages (0.2.5)\n","Requirement already satisfied: EasyProcess in /usr/local/lib/python3.6/dist-packages (from pyvirtualdisplay) (0.2.10)\n","Requirement already satisfied: piglet in /usr/local/lib/python3.6/dist-packages (1.0.0)\n","Requirement already satisfied: piglet-templates in /usr/local/lib/python3.6/dist-packages (from piglet) (0.5.1)\n","Requirement already satisfied: Parsley in /usr/local/lib/python3.6/dist-packages (from piglet-templates->piglet) (1.3)\n","Requirement already satisfied: attrs in /usr/local/lib/python3.6/dist-packages (from piglet-templates->piglet) (19.3.0)\n","Requirement already satisfied: astunparse in /usr/local/lib/python3.6/dist-packages (from piglet-templates->piglet) (1.6.3)\n","Requirement already satisfied: markupsafe in /usr/local/lib/python3.6/dist-packages (from piglet-templates->piglet) (1.1.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from astunparse->piglet-templates->piglet) (0.34.2)\n","Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from astunparse->piglet-templates->piglet) (1.12.0)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vUSaUTcgat3F","colab_type":"text"},"source":["To activate virtual display we need to run a script once for training an agent, as follows:"]},{"cell_type":"code","metadata":{"id":"lD2uXzfr1yef","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":105},"outputId":"c5d2df67-5c21-4598-8f9e-ef93bf31dd4e","executionInfo":{"status":"ok","timestamp":1584255831018,"user_tz":420,"elapsed":20375,"user":{"displayName":"Aaron Wong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiS9mCZyE463_E_8tYQyoLyZY7HPjP2KsUJDdWjQ=s64","userId":"04748882517196628077"}}},"source":["! apt-get install x11-utils\n"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","x11-utils is already the newest version (7.7+3build1).\n","0 upgraded, 0 newly installed, 0 to remove and 25 not upgraded.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Pn1IAnsDYK4V","colab_type":"code","outputId":"e26e15b5-363a-4fdc-8a04-437ca24e12ec","executionInfo":{"status":"ok","timestamp":1584255831019,"user_tz":420,"elapsed":20363,"user":{"displayName":"Aaron Wong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiS9mCZyE463_E_8tYQyoLyZY7HPjP2KsUJDdWjQ=s64","userId":"04748882517196628077"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["from pyvirtualdisplay import Display\n","display = Display(visible=0, size=(1400, 900))\n","display.start()"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<Display cmd_param=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '1400x900x24', ':1005'] cmd=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '1400x900x24', ':1005'] oserror=None return_code=None stdout=\"None\" stderr=\"None\" timeout_happened=False>"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"AutUqpSRYN1W","colab_type":"code","colab":{}},"source":["# This code creates a virtual display to draw game images on. \n","# If you are running locally, just ignore it\n","import os\n","if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\"))==0:\n","    !bash ../xvfb start\n","    %env DISPLAY=:1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jh10T5veI1zk","colab_type":"code","colab":{}},"source":["import gym\n","from gym import logger as gymlogger\n","from gym.wrappers import Monitor\n","gymlogger.set_level(40) # error only\n","import tensorflow as tf\n","import numpy as np\n","import random\n","import matplotlib\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import math\n","import glob\n","import io\n","import base64\n","from IPython.display import HTML\n","\n","from IPython import display as ipythondisplay"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JWNVK4NUJUCl","colab_type":"code","colab":{}},"source":["\"\"\"\n","Utility functions to enable video recording of gym environment and displaying it\n","To enable video, just do \"env = wrap_env(env)\"\"\n","\"\"\"\n","\n","def show_video():\n","  mp4list = glob.glob('video/*.mp4')\n","  if len(mp4list) > 0:\n","    mp4 = mp4list[0]\n","    video = io.open(mp4, 'r+b').read()\n","    encoded = base64.b64encode(video)\n","    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n","                loop controls style=\"height: 400px;\">\n","                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n","             </video>'''.format(encoded.decode('ascii'))))\n","  else: \n","    print(\"Could not find video\")\n","    \n","\n","def wrap_env(env):\n","  env = Monitor(env, './video', force=True)\n","  return env"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3-ATQfrfYkM7","colab_type":"text"},"source":["# OpenAI Gym\n","\n","OpenAI gym is a python library that wraps many classical decision problems including robot control, videogames and board games. We will use the environments it provides to test our algorithms on interesting decision problems .\n","\n","This gym [wiki](https://github.com/openai/gym/wiki) explains more about the environment. \n","\n","Good general-purpose agents don't need to know the semantics of the observations: they can learn how to map observations to actions to maximize reward without any prior knowledge.\n","\n","That said, the meaning of Box(4,)\n","[position of cart, velocity of cart, angle of pole, rotation rate of pole]. Defined at https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py#L75"]},{"cell_type":"markdown","metadata":{"id":"5feQRBXTKqGI","colab_type":"text"},"source":["## Explore environment object\n","\n","- env.observation_space\n","- env.action_space \n","\n","- env.reset() : reset environment to initial state, return first observation\n","- env.render(): show current environment state (a more colorful version :) )\n","- env.step(action) : commit action a and return (new observation, reward, is done, info)"]},{"cell_type":"markdown","metadata":{"id":"RvFDvAsvH70n","colab_type":"text"},"source":["## CartPole"]},{"cell_type":"code","metadata":{"id":"1Ea_5qNYIBsl","colab_type":"code","outputId":"6474bf76-c922-4989-ab83-50ab9bd8ef3c","executionInfo":{"status":"ok","timestamp":1584255831343,"user_tz":420,"elapsed":20640,"user":{"displayName":"Aaron Wong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiS9mCZyE463_E_8tYQyoLyZY7HPjP2KsUJDdWjQ=s64","userId":"04748882517196628077"}},"colab":{"base_uri":"https://localhost:8080/","height":140}},"source":["import gym\n","env = gym.make('CartPole-v0')\n","env = wrap_env(env) \n","\n","print('observation space:', env.observation_space)\n","print('action space:', env.action_space)\n","\n","obs = env.reset()\n","#env.render()\n","\n","print('initial observation:', obs)\n","\n","action = env.action_space.sample()  # take a random action\n","\n","obs, r, done, info = env.step(action)\n","print('next observation:', obs)\n","print('reward:', r)\n","print('done:', done)\n","print('info:', info)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["observation space: Box(4,)\n","action space: Discrete(2)\n","initial observation: [-0.00149949  0.01400551 -0.03165232  0.0158234 ]\n","next observation: [-0.00121938 -0.18064854 -0.03133585  0.298354  ]\n","reward: 1.0\n","done: False\n","info: {}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TLeHP_dxLReW","colab_type":"text"},"source":["### Display Video"]},{"cell_type":"code","metadata":{"id":"bhsj7BTPHepg","colab_type":"code","outputId":"ca352b18-7a45-4ca2-fade-7273788b7ef3","executionInfo":{"status":"ok","timestamp":1584262301008,"user_tz":420,"elapsed":911,"user":{"displayName":"Aaron Wong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiS9mCZyE463_E_8tYQyoLyZY7HPjP2KsUJDdWjQ=s64","userId":"04748882517196628077"}},"colab":{"base_uri":"https://localhost:8080/","height":807}},"source":["'''CartPole problem use random action'''\n","import gym\n","env = gym.make('CartPole-v0')\n","env = wrap_env(env)  # defined before for rendering online\n","\n","observation = env.reset()\n","    \n","while True:\n","  env.render()\n","  \n","  # your agent goes here\n","  action = env.action_space.sample()   # take a random action\n","  observation, reward, done, info = env.step(action) \n","  print(reward)\n","   \n","  if done: \n","    break;\n","            \n","env.close()\n","show_video()"],"execution_count":27,"outputs":[{"output_type":"stream","text":["1.0\n","1.0\n","1.0\n","1.0\n","1.0\n","1.0\n","1.0\n","1.0\n","1.0\n","1.0\n","1.0\n","1.0\n","1.0\n","1.0\n","1.0\n","1.0\n","1.0\n","1.0\n","1.0\n","1.0\n","1.0\n","1.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<video alt=\"test\" autoplay \n","                loop controls style=\"height: 400px;\">\n","                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n","             </video>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"hTN0hCKZIGdP","colab_type":"text"},"source":["## MountainCar"]},{"cell_type":"markdown","metadata":{"id":"6uAbJY54Pjy4","colab_type":"text"},"source":["### Random Action"]},{"cell_type":"code","metadata":{"id":"Vcj2F7fkYSUR","colab_type":"code","outputId":"5589b243-8777-4b19-e640-f1a47488c7be","executionInfo":{"status":"error","timestamp":1584255831348,"user_tz":420,"elapsed":20618,"user":{"displayName":"Aaron Wong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiS9mCZyE463_E_8tYQyoLyZY7HPjP2KsUJDdWjQ=s64","userId":"04748882517196628077"}},"colab":{"base_uri":"https://localhost:8080/","height":385}},"source":["import gym\n","env = gym.make(\"MountainCar-v0\")\n","env = wrap_env(env)\n","\n","#\n","# explore MountainCar environment\n","#\n","plt.imshow(env.render('rgb_array'))\n","print(\"Observation space:\", env.observation_space)\n","print(\"Action space:\", env.action_space)\n","\n","#\n","# take random actions and show the video result\n","# In MountainCar, observation is just two numbers: \n","# car position and velocity\n","#\n","observation = env.reset()\n","print(\"initial observation code:\", observation)\n","\n","    \n","while True:\n","  env.render()\n","  \n","  # your agent goes here\n","  action = env.action_space.sample()   # take a random action\n","  observation, reward, done, info = env.step(action) \n","  print(reward)\n","   \n","  if done: \n","    break;\n","            \n","env.close()\n","show_video()"],"execution_count":26,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-33e03d24d628>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# explore MountainCar environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Observation space:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Action space:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/envs/classic_control/mountain_car.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_geom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcartrans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_translation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_position\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_height\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcartrans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_rotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'MountainCarEnv' object has no attribute 'state'"]}]},{"cell_type":"markdown","metadata":{"id":"N-m03oAaPoRE","colab_type":"text"},"source":["### Assigned Action"]},{"cell_type":"code","metadata":{"id":"cJJlwrykZRkL","colab_type":"code","colab":{}},"source":["import gym\n","env = gym.make(\"MountainCar-v0\")\n","env = wrap_env(env)\n","\n","# explore MountainCar environment\n","#\n","plt.imshow(env.render('rgb_array'))\n","print(\"Observation space:\", env.observation_space)\n","print(\"Action space:\", env.action_space)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0MOhVFFiQNxq","colab_type":"code","colab":{}},"source":["# Explore a little bit\n","obs = env.reset()\n","print(\"initial observation code:\", obs)\n","print(\"taking action 2 (right)\")\n","new_obs, reward, is_done, _ = env.step(2)\n","\n","print(\"new observation code:\", new_obs)\n","print(\"reward:\", reward)\n","print(\"is game over?:\", is_done)\n","\n","# As you can see, the car has moved to the right slightly (around 0.0005)\n","plt.imshow(env.render('rgb_array'))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9rojutbnRgZV","colab_type":"text"},"source":["### MountainCar Video: Keep moving right by assignment"]},{"cell_type":"code","metadata":{"id":"HyS4V0m9Rkvl","colab_type":"code","colab":{}},"source":["import gym\n","env = gym.make(\"MountainCar-v0\")\n","env = wrap_env(env)\n","\n","#\n","# explore MountainCar environment\n","#\n","# plt.imshow(env.render('rgb_array'))\n","print(\"Observation space:\", env.observation_space)\n","print(\"Action space:\", env.action_space)\n","\n","#\n","# keep moving right and show the video result\n","# In MountainCar, observation is just two numbers: \n","# car position and velocity\n","#\n","observation = env.reset()\n","print(\"initial observation code:\", observation)\n","\n","    \n","#while True:\n","for _ in range(1000):\n","  env.render()\n","  \n","  # your agent goes here\n","  print(\"taking action 2 (right)\")\n","  action = 2   \n","  observation, reward, done, info = env.step(action) \n","  print(reward)\n","   \n","  if done: \n","    env.reset()\n","            \n","env.close()\n","show_video()\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XQ_UXi_KZcJK","colab_type":"text"},"source":["### MountainCar with heuristic action strategy"]},{"cell_type":"code","metadata":{"id":"z2btCBLfbiMc","colab_type":"code","colab":{}},"source":["import gym\n","from gym.envs.classic_control.mountain_car import MountainCarEnv"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ziwJH9-7ZvcQ","colab_type":"code","colab":{}},"source":["#\n","# create env manually to set time limit. Please don't change this.\n","#\n","TIME_LIMIT = 250\n","env = gym.wrappers.TimeLimit(MountainCarEnv(), max_episode_steps=TIME_LIMIT + 1)\n","env = wrap_env(env)\n","\n","obs = env.reset()\n","actions = {'left': 0, 'stop': 1, 'right': 2}\n","\n","#\n","# prepare \"display\"\n","#\n","#%matplotlib notebook\n","#fig = plt.figure()\n","#ax = fig.add_subplot(111)\n","#fig.show()\n","\n","#\n","# simple heuristic policy\n","#\n","def policy(t):\n","    if t>50 and t<100:\n","        return actions['left']\n","    else:\n","        return actions['right']\n","\n","\n","for t in range(TIME_LIMIT):\n","    \n","    #\n","    # change the line below to reach the flag\n","    #\n","    obs, r, done, _ = env.step(policy(t))\n","    \n","    # draw game image on display\n","    #ax.clear()\n","    #ax.imshow(env.render('rgb_array'))\n","    #fig.canvas.draw()\n","    \n","    if done:\n","        print(\"Well done!\")\n","        break\n","#    else:    \n","#        print(\"Time limit exceeded. Try again.\")\n","\n","env.close()\n","show_video()"],"execution_count":0,"outputs":[]}]}